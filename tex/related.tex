TODO: What other methods exist? What are the differences? What are the difficulties with other methods? How does it compare to a baseline method?

\href{https://www.math.leidenuniv.nl/scripties/BSC-Obbens.pdf}{Interisting stuff} \cite{obbens2014inference}


\subsection{Markov logic network}

TODO: probabilistic logic -> enabling uncertain inference

TODO: \href{https://en.wikipedia.org/wiki/Markov_logic_network}{wikipedia article}

TODO: \cite{koller2009probabilistic} chapter 20 learning undirected models

TODO: Main (first article about this) \cite{richardson2006markov}

\subsection{Markov chain}

TODO: Markov chain/ Markov process has time restrictions, Markov network has spatial restrictions

TODO: \href{https://en.wikipedia.org/wiki/Markov_chain}{wikipedia article}

TODO: image


\subsection{Bayesian networks}

TODO: probabilistic directed acyclic graphical model

TODO: \href{https://en.wikipedia.org/wiki/Bayesian_network}{wikipedia article}

TODO: image

TODO: Probabilistic reasoning in intelligent systems:Networks of Plausible Inference" written by Judea Pearl, chapter 3: Markov and Bayesian Networks:Two Graphical Representations of Probabilistic Knowledge, p.116:
The main weakness of Markov networks is their inability to represent induced and non-transitive dependencies; two independent variables will be directly connected by an edge, merely because some other variable depends on both. As a result, many useful independencies go unrepresented in the network. To overcome this deficiency, Bayesian networks use the richer language of directed graphs, where the directions of the arrows permit us to distinguish genuine dependencies from spurious dependencies induced by hypothetical observations.


\subsection{Hopfield network}

TODO: recurrent artificial neural network

TODO: \href{https://en.wikipedia.org/wiki/Hopfield_network}{wikipedia article}

